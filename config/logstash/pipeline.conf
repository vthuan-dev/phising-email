# config/logstash/pipeline.conf
input {
  beats {
    port => 5045
  }
}

filter {
  # Parse JSON from Filebeat
  if [logtype] == "email_events" {
    # Ensure proper field types
    mutate {
      convert => {
        "ml_score" => "float"
        "llm_confidence" => "float"
        "llm_latency_ms" => "integer"
        "suspicious_keywords" => "integer"
        "url_in_blacklist" => "boolean"
      }
    }

    # Parse timestamp
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }

    # Extract sender IP from headers if available
    if [headers][x_originating_ip] and [headers][x_originating_ip] != "" {
      mutate { add_field => { "sender_ip" => "%{[headers][x_originating_ip]}" } }
    } else if [headers][received] {
      grok {
        match => { "[headers][received]" => [
          # Capture first IP (v4 or v6) found in Received chain
          "(?<sender_ip>(?:\d{1,3}\.){3}\d{1,3}|[A-Fa-f0-9:]{2,})"
        ]}
        tag_on_failure => ["_received_parse_failed"]
      }
    }
    mutate { gsub => ["sender_ip", "[<>\[\]]", ""] }

    # Prefer accurate public IPv4 from Received chain â†’ sender_ip_v4
    ruby {
      code => '
        begin
          rec = event.get("[headers][received]").to_s
          ips = rec.scan(/(?:(?:25[0-5]|2[0-4]\d|1?\d?\d)\.){3}(?:25[0-5]|2[0-4]\d|1?\d?\d)/)
          if ips && !ips.empty?
            require "ipaddr"
            pub = ips.find do |x|
              ip = IPAddr.new(x) rescue nil
              next false unless ip && ip.ipv4?
              !ip.private? && !ip.loopback? &&
              (IPAddr.new("100.64.0.0/10") rescue nil).include?(ip) == false &&
              (IPAddr.new("169.254.0.0/16") rescue nil).include?(ip) == false
            end
            event.set("sender_ip_v4", pub) if pub
          end
        rescue => e
          # ignore
        end
      '
    }

    # Add sender domain extraction
    if [sender] {
      grok {
        match => { "sender" => "(?<sender_domain>[^@]+@(?<sender_domain_only>[^@]+))" }
        add_field => { "sender_domain" => "%{sender_domain_only}" }
        tag_on_failure => ["_sender_parse_failed"]
      }
    }

    # Create subject hash for deduplication
    if [subject] {
      fingerprint {
        source => "subject"
        target => "subject_hash"
        method => "SHA256"
      }
    }

    # GeoIP lookup if sender_ip exists
    if [sender_ip] and [sender_ip] != "" {
      geoip {
        source => "sender_ip"
        target => "geoip"
        add_tag => ["geoip"]
      }
    }

    # GeoIP for the refined IPv4 (public only)
    if [sender_ip_v4] and [sender_ip_v4] != "" {
      geoip {
        source => "sender_ip_v4"
        target => "geoip_v4"
        add_tag => ["geoip_v4"]
      }
    }

    # Add processing timestamp
    mutate {
      add_field => { "processed_at" => "%{@timestamp}" }
    }

    # Truncate long fields to prevent mapping explosion
    if [llm_explanation] {
      truncate {
        fields => ["llm_explanation"]
        length_bytes => 1000
      }
    }

    if [body_excerpt] {
      truncate {
        fields => ["body_excerpt"]
        length_bytes => 2000
      }
    }

    # Add risk level based on scores
    ruby {
      code => "
        ml_score = event.get('ml_score').to_f
        llm_confidence = event.get('llm_confidence').to_f
        
        if ml_score >= 0.85 or llm_confidence >= 0.85
          event.set('risk_level', 'high')
        elsif ml_score >= 0.6 or llm_confidence >= 0.6
          event.set('risk_level', 'medium')
        else
          event.set('risk_level', 'low')
        end
      "
    }

    # Remove temporary fields
    mutate {
      remove_field => ["host", "agent", "@version", "input", "ecs", "log"]
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "phish-mail-%{+YYYY.MM.dd}"
  }

  # Debug output (remove in production)
  stdout {
    codec => rubydebug
  }
}
